{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecffcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentencepiece ONLY WORKS WITH PYTHON 3.12 or smaller, not 3.13!\n",
    "#!pip install torch transformers tqdm pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25e1e324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentencepiece\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d899c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dgars\\miniconda3\\envs\\ml24\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdfd6f4",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb46ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "CSV_PATH = \"../data/results_with_sequence.csv\"  # Path to the CSV file\n",
    "PROC_DIR = Path(\"../data/processed\")  # Directory to save processed embeddings\n",
    "PROC_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9262f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Custom collate function for padding\n",
    "def collate_fn(batch):\n",
    "    accessions = [item['accession'] for item in batch]\n",
    "    labels = torch.tensor([item['label'] for item in batch], dtype=torch.long)\n",
    "    lengths = torch.tensor([item['length'] for item in batch], dtype=torch.long)\n",
    "    \n",
    "    # Pad residue labels to the same length\n",
    "    residue_labels = pad_sequence([item['residue_labels'] for item in batch], batch_first=True, padding_value=0)\n",
    "    \n",
    "    return {\n",
    "        'accession': accessions,\n",
    "        'label': labels,\n",
    "        'residue_labels': residue_labels,\n",
    "        'length': lengths\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b45b5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the project root to sys.path\n",
    "project_root = Path(os.getcwd()).parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from data.dataloader import ProteinResidueDataset\n",
    "\n",
    "# Load the dataset using the new data class\n",
    "dataset = ProteinResidueDataset(CSV_PATH)\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906adcb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession</th>\n",
       "      <th>length</th>\n",
       "      <th>source_database</th>\n",
       "      <th>fragments</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A0A003</td>\n",
       "      <td>340</td>\n",
       "      <td>unreviewed</td>\n",
       "      <td>[{'start': 15, 'end': 249}]</td>\n",
       "      <td>MSSDTHGTDLADGDVLVTGAAGFIGSHLVTELRNSGRNVVAVDRRP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A009GZV8</td>\n",
       "      <td>323</td>\n",
       "      <td>unreviewed</td>\n",
       "      <td>[{'start': 3, 'end': 208}]</td>\n",
       "      <td>MNVLITGGTGFIGKQIAKEILKAGSLTLDDNKPQSIDKIILFDAFA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A009H3J1</td>\n",
       "      <td>335</td>\n",
       "      <td>unreviewed</td>\n",
       "      <td>[{'start': 2, 'end': 260}]</td>\n",
       "      <td>MILVTGGLGFIGSHIALSLMAQGQEVVIVDNLANSTLQTLERLEFI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A009H7U9</td>\n",
       "      <td>338</td>\n",
       "      <td>unreviewed</td>\n",
       "      <td>[{'start': 4, 'end': 263}]</td>\n",
       "      <td>MAKILVTGGAGYIGSHTCVELLNAGHEVIVFDNLSNSSEESLKRVQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A009HJQ2</td>\n",
       "      <td>301</td>\n",
       "      <td>unreviewed</td>\n",
       "      <td>[{'start': 5, 'end': 220}]</td>\n",
       "      <td>MNKNVLITGASGFIGTHLIKFLLQKNYNVIAVTRQAGKASDHPALQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0A009HLV6</td>\n",
       "      <td>216</td>\n",
       "      <td>unreviewed</td>\n",
       "      <td>[{'start': 17, 'end': 193}]</td>\n",
       "      <td>MDNLNNAKKDNFSRKTILVTGAAGFIGSRLIVELLREGHQVIAALR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A0A009HNL3</td>\n",
       "      <td>323</td>\n",
       "      <td>unreviewed</td>\n",
       "      <td>[{'start': 3, 'end': 206}]</td>\n",
       "      <td>MNVLITGGTGFIGKQIAKEILKTGSLTLDGKQAKPIDKIILFDAFA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A0A009HPX5</td>\n",
       "      <td>338</td>\n",
       "      <td>unreviewed</td>\n",
       "      <td>[{'start': 4, 'end': 263}]</td>\n",
       "      <td>MAKILVTGGAGYIGSHTCVELLEAGHEVIVFDNLSNSSKESLNRVQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A0A009HQP5</td>\n",
       "      <td>301</td>\n",
       "      <td>unreviewed</td>\n",
       "      <td>[{'start': 5, 'end': 220}]</td>\n",
       "      <td>MNKNVLITGASGFIGTHLIRFLLQKNYNVIAVTRQAGRESDHPALQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A0A009I037</td>\n",
       "      <td>271</td>\n",
       "      <td>unreviewed</td>\n",
       "      <td>[{'start': 14, 'end': 195}]</td>\n",
       "      <td>MHILFIGYGKTSQRVAKQLFEKEHQITTISRSVKTDSYATHLVQDI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accession  length source_database                    fragments  \\\n",
       "0      A0A003     340      unreviewed  [{'start': 15, 'end': 249}]   \n",
       "1  A0A009GZV8     323      unreviewed   [{'start': 3, 'end': 208}]   \n",
       "2  A0A009H3J1     335      unreviewed   [{'start': 2, 'end': 260}]   \n",
       "3  A0A009H7U9     338      unreviewed   [{'start': 4, 'end': 263}]   \n",
       "4  A0A009HJQ2     301      unreviewed   [{'start': 5, 'end': 220}]   \n",
       "5  A0A009HLV6     216      unreviewed  [{'start': 17, 'end': 193}]   \n",
       "6  A0A009HNL3     323      unreviewed   [{'start': 3, 'end': 206}]   \n",
       "7  A0A009HPX5     338      unreviewed   [{'start': 4, 'end': 263}]   \n",
       "8  A0A009HQP5     301      unreviewed   [{'start': 5, 'end': 220}]   \n",
       "9  A0A009I037     271      unreviewed  [{'start': 14, 'end': 195}]   \n",
       "\n",
       "                                            sequence  \n",
       "0  MSSDTHGTDLADGDVLVTGAAGFIGSHLVTELRNSGRNVVAVDRRP...  \n",
       "1  MNVLITGGTGFIGKQIAKEILKAGSLTLDDNKPQSIDKIILFDAFA...  \n",
       "2  MILVTGGLGFIGSHIALSLMAQGQEVVIVDNLANSTLQTLERLEFI...  \n",
       "3  MAKILVTGGAGYIGSHTCVELLNAGHEVIVFDNLSNSSEESLKRVQ...  \n",
       "4  MNKNVLITGASGFIGTHLIKFLLQKNYNVIAVTRQAGKASDHPALQ...  \n",
       "5  MDNLNNAKKDNFSRKTILVTGAAGFIGSRLIVELLREGHQVIAALR...  \n",
       "6  MNVLITGGTGFIGKQIAKEILKTGSLTLDGKQAKPIDKIILFDAFA...  \n",
       "7  MAKILVTGGAGYIGSHTCVELLEAGHEVIVFDNLSNSSKESLNRVQ...  \n",
       "8  MNKNVLITGASGFIGTHLIRFLLQKNYNVIAVTRQAGRESDHPALQ...  \n",
       "9  MHILFIGYGKTSQRVAKQLFEKEHQITTISRSVKTDSYATHLVQDI...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e283f34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MSSDTHGTDLADGDVLVTGAAGFIGSHLVTELRNSGRNVVAVDRRPLPDDLESTSPPFTGSLREIRGDLNSLNLVDCLKNISTVFHLAALPGVRPSWTQFPEYLRCNVLATQRLMEACVQAGVERVVVASSSSVYGGADGVMSEDDLPRPLSPYGVTKLAAERLALAFAARGDAELSVGALRFFTVYGPGQRPDMFISRLIRATLRGEPVEIYGDGTQLRDFTHVSDVVRALMLTASVRDRGSAVLNIGTGSAVSVNEVVSMTAELTGLRPCTAYGSARIGDVRSTTADVRQAQSVLGFTARTGLREGLATQIEWTRRSLSGAEQDTVPVGGSSVSVPRL'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sequence\"].iloc[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a972c0",
   "metadata": {},
   "source": [
    "## Load Embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18341ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ProtT5 model and tokenizer\n",
    "def load_prott5():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\", do_lower_case=False, legacy=True)\n",
    "    model = T5EncoderModel.from_pretrained(\"Rostlab/prot_t5_xl_half_uniref50-enc\")\n",
    "    if device.type == \"cuda\":\n",
    "        print(\"Moving model to GPU\")\n",
    "        model = model.half()\n",
    "    else:\n",
    "        print(\"Moving model to CPU - not using half precision\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return tokenizer, model, device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1721eb23",
   "metadata": {},
   "source": [
    "## Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ac133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(loader, tokenizer, model, device):\n",
    "    for batch in tqdm(loader, desc=\"Generating embeddings\"):\n",
    "        for i in range(len(batch['accession'])):\n",
    "            accession = batch['accession'][i]\n",
    "            sequence = batch['residue_labels'][i]\n",
    "            length = batch['length'][i].item()  # Convert tensor to int\n",
    "\n",
    "            # Convert the sequence tensor to a string\n",
    "            raw_seq = \"\".join(map(str, sequence[:length].tolist()))\n",
    "            raw_seq = re.sub(r\"[UZOB]\", \"X\", raw_seq)  # Replace invalid characters\n",
    "\n",
    "            if len(raw_seq) > 1022:\n",
    "                print(f\"Skipping {accession}: too long\")\n",
    "                continue\n",
    "\n",
    "            seq = \"<AA2fold> \" + \" \".join(list(raw_seq))\n",
    "            tokens = tokenizer.batch_encode_plus(\n",
    "                [seq], return_tensors=\"pt\", padding=True, add_special_tokens=True\n",
    "            ).to(device)\n",
    "\n",
    "            # Generate embeddings\n",
    "            with torch.no_grad():\n",
    "                output = model(**tokens).last_hidden_state.float().cpu()\n",
    "\n",
    "            # Save embeddings and labels\n",
    "            emb = output[0, 1:length + 1]  # Remove prefix token and padding\n",
    "            labels = sequence[:length]  # Use only the original length\n",
    "            torch.save(emb, PROC_DIR / f\"{accession}_embedding.pt\")\n",
    "            torch.save(labels, PROC_DIR / f\"{accession}_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049cb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "tokenizer, model, device = load_prott5()\n",
    "generate_embeddings(loader, tokenizer, model, device)\n",
    "print(\"Embedding generation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protpred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
